import uvicorn
from fastapi import FastAPI, Request, Depends, Query
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from pandas.core._numba import executor
from sqlalchemy.orm import Session
from sqlalchemy import func
from apscheduler.schedulers.background import BackgroundScheduler
from starlette.responses import RedirectResponse
from fastapi import HTTPException

from app.services.sync_service import sync_yesterday_commits
from app.database.models import CommitRecord
from app.database.session import get_db
from sqlalchemy import func
from datetime import datetime, timedelta, date
import atexit
import asyncio
import os
from fastapi.responses import Response
import csv
from io import StringIO
import pandas as pd
from pytz import timezone
import re

app = FastAPI(title="GitLab æäº¤ç»Ÿè®¡æœåŠ¡")

# ================================
# ğŸ“ æŒ‚è½½é™æ€æ–‡ä»¶å’Œæ¨¡æ¿
# ================================
current_dir = os.path.dirname(os.path.abspath(__file__))
static_dir = os.path.join(current_dir, "static")
templates_dir = os.path.join(current_dir, "templates")

app.mount("/static", StaticFiles(directory=static_dir), name="static")
templates = Jinja2Templates(directory=templates_dir)

scheduler = BackgroundScheduler()


@app.get("/")
def dashboard(
        request: Request,
        days: int = Query(None),
        start_date: str = Query(None),
        end_date: str = Query(None),
        search: str = Query(None),
        page: int = Query(1, ge=1),
        db: Session = Depends(get_db)
):
    # 1. ç¡®å®šæ—¶é—´èŒƒå›´
    if days is not None:
        # ç›®æ ‡ï¼šè·å–è¿‡å» N ä¸ªå®Œæ•´çš„è‡ªç„¶æ—¥ï¼ˆä¸åŒ…å«ä»Šå¤©ï¼‰
        today = datetime.now().date()  # ä¾‹å¦‚ï¼š2025-09-04
        start_date_obj = today - timedelta(days=days)  # ä¾‹å¦‚ï¼š9.4 - 1 = 9.3
        end_date_obj = today - timedelta(days=1)  # ä¾‹å¦‚ï¼š9.4 - 1 = 9.3ï¼ˆæœ€åä¸€å¤©æ˜¯æ˜¨å¤©ï¼‰

        # è®¾ç½®æ—¶é—´è¾¹ç•Œï¼šsince = 00:00:00, until = 23:59:59
        since = datetime.combine(start_date_obj, datetime.min.time())  # 9.3 00:00:00
        until = datetime.combine(end_date_obj, datetime.max.time())  # 9.3 23:59:59
    else:
        # è‡ªå®šä¹‰æ—¥æœŸèŒƒå›´
        if start_date:
            since = datetime.fromisoformat(start_date)
            # ä¿æŒä¸ºå½“å¤© 00:00:00ï¼ˆå‰ç«¯è¾“å…¥çš„æ˜¯æ—¥æœŸï¼‰
        else:
            since = None

        if end_date:
            # å…³é”®ï¼šend_date åº”åŒ…å«å½“å¤©çš„ 23:59:59
            end_date_obj = datetime.fromisoformat(end_date)
            until = datetime.combine(end_date_obj, datetime.max.time())
        else:
            until = datetime.now()

    # 2. æŸ¥è¯¢æœ‰æäº¤è®°å½•çš„äºº
    query = db.query(
        CommitRecord.author_name,
        func.sum(CommitRecord.additions).label("additions"),
        func.sum(CommitRecord.deletions).label("deletions")
    ).group_by(CommitRecord.author_name)

    if since:
        query = query.filter(CommitRecord.commit_date >= since)
    if until:
        query = query.filter(CommitRecord.commit_date <= until)

    result = query.all()

    # è½¬æˆå­—å…¸ï¼šauthor_name -> {additions, deletions}
    commit_data = {
        row.author_name: {
            "additions": int(row.additions),
            "deletions": int(row.deletions)
        }
        for row in result
    }

    # 3. è¯»å– Excel ä¸­çš„æ‰€æœ‰å‘˜å·¥ï¼ˆå«éƒ¨é—¨ï¼‰
    all_employees = load_all_employees()

    # 4. æœç´¢è¿‡æ»¤ï¼ˆæŒ‰å§“åï¼‰
    if search:
        # all_employees = [e for e in all_employees if search in search_names]
        search_terms = re.split(r'[,;\s\n]+', search)
        search_terms = [s.strip() for s in search_terms if s.strip()]
        print(f"ğŸ” æ¨¡ç³Šæœç´¢å…³é”®è¯: {search_terms}")

        # æ¨¡ç³ŠåŒ¹é…ï¼šåå­—ä¸­åŒ…å«ä»»æ„ä¸€ä¸ªå…³é”®è¯
        all_employees = [
            e for e in all_employees
            if any(term in e["name"] for term in search_terms)
        ]

    # 5. åˆå¹¶æ•°æ®ï¼šæ‰€æœ‰äºº + è¡¥ 0
    full_data = []
    for emp in all_employees:
        name = emp["name"]
        if name in commit_data:
            add = commit_data[name]["additions"]
            dels = commit_data[name]["deletions"]
        else:
            add, dels = 0, 0

        full_data.append({
            "author_name": name,
            "department": emp["department"],
            "additions": add,
            "deletions": dels,
            "net_lines": add - dels
        })

    # 6. æŒ‰æ–°å¢è¡Œæ•°æ’åº
    full_data.sort(key=lambda x: x["additions"], reverse=True)

    # 7. åˆ†é¡µ
    total = len(full_data)
    page_size = 15
    start_idx = (page - 1) * page_size
    end_idx = start_idx + page_size
    data = full_data[start_idx:end_idx]

    if page < 1:
        page = 1

    # è®¡ç®—æœ€å¤§é¡µç 
    max_page = (total // page_size) + (1 if total % page_size > 0 else 0)
    if max_page == 0:
        max_page = 1  # è‡³å°‘ä¸€é¡µ

    # å¦‚æœå½“å‰é¡µç å¤§äºæœ€å¤§é¡µç ï¼Œåˆ™é‡å®šå‘åˆ°æœ€åä¸€é¡µ
    # âœ… é˜²æ­¢ page è¶Šç•Œï¼Œè‡ªåŠ¨è·³è½¬
    if page > max_page and max_page > 1:
        params = request.query_params.copy()
        params = dict(params)  # è½¬ä¸ºæ™®é€šå­—å…¸
        params["page"] = max_page
        url = request.url.path + "?" + "&".join([f"{k}={v}" for k, v in params.items()])
        return RedirectResponse(url=url)

    # âœ… æ­£å¸¸åˆ†é¡µ
    data = full_data[start_idx:end_idx]

    return templates.TemplateResponse(
        "dashboard.html",
        context={
            "request": request,
            "data": data,
            "total": total,
            "page": page,
            "page_size": page_size,
            "max_page": max_page,
            "search": search or "",
            "days": days,
            "start_date": start_date,
            "end_date": end_date,
        }
    )


@app.get("/export")
def export_data(
        days: int = Query(None),
        start_date: str = Query(None),
        end_date: str = Query(None),
        search: str = Query(None),
        db: Session = Depends(get_db)
):
    # æ—¶é—´èŒƒå›´
    if days is not None:
        since = datetime.now() - timedelta(days=days)
        until = datetime.now()
        data_range = f"last_{days}_days"
    else:
        since = datetime.fromisoformat(start_date) if start_date else None
        until = datetime.fromisoformat(end_date) if end_date else datetime.now()
        start_str = since.strftime("%m%d") if since else "from_start"
        end_str = until.strftime("%m%d")
        data_range = f"{start_str}_{end_str}"

    # 1. æŸ¥è¯¢æœ‰æäº¤çš„äºº
    query = db.query(
        CommitRecord.author_name,
        func.sum(CommitRecord.additions).label("additions"),
        func.sum(CommitRecord.deletions).label("deletions")
    ).group_by(CommitRecord.author_name)

    if since:
        query = query.filter(CommitRecord.commit_date >= since)
    if until:
        query = query.filter(CommitRecord.commit_date <= until)

    result = query.all()
    commit_data = {
        row.author_name: {
            "additions": int(row.additions),
            "deletions": int(row.deletions)
        }
        for row in result
    }

    # 2. è¯»å–æ‰€æœ‰å‘˜å·¥ï¼ˆå«éƒ¨é—¨ï¼‰
    all_employees = load_all_employees()
    if search:
        all_employees = [e for e in all_employees if search in e["name"]]
    # 3. åˆå¹¶æ•°æ®

    full_data = []
    for emp in all_employees:
        name = emp["name"]
        if name in commit_data:
            add = commit_data[name]["additions"]
            dels = commit_data[name]["deletions"]
        else:
            add, dels = 0, 0

        full_data.append({
            "author_name": name,
            "department": emp["department"],
            "additions": add,
            "deletions": dels,
            "net_lines": add - dels
        })

    # 4. æ’åº
    full_data.sort(key=lambda x: x["additions"], reverse=True)

    # 5. ç”Ÿæˆ CSV
    si = StringIO()
    writer = csv.writer(si, quoting=csv.QUOTE_ALL)
    writer.writerow(["æ’å", "å§“å", "éƒ¨é—¨", "æ–°å¢è¡Œæ•°", "åˆ é™¤è¡Œæ•°", "å‡€å¢è¡Œæ•°"])  # âœ… å«éƒ¨é—¨

    for idx, row in enumerate(full_data, start=1):
        writer.writerow([
            idx,
            row["author_name"],
            row["department"],
            row["additions"],
            row["deletions"],
            row["net_lines"]
        ])

    content = si.getvalue()
    si.close()

    today = datetime.now().strftime("%m%d")
    filename = f"{data_range}.csv"

    return Response(
        content=content,
        media_type="text/csv",
        headers={"Content-Disposition": f"attachment; filename={filename}"}
    )


@app.get("/detail")
def detail_page(
    request: Request,
    author: str = Query(..., description="å¼€å‘è€…å§“å"),
    days: int = Query(None, ge=1, le=180),
    start_date: str = Query(None),
    end_date: str = Query(None),
    db: Session = Depends(get_db)
):
    """
    æ¸²æŸ“å¼€å‘è€…è¯¦æƒ…é¡µé¢
    é»˜è®¤æ˜¾ç¤ºè¿‡å»7å¤©æ•°æ®
    """
    if not author:
        raise HTTPException(status_code=400, detail="ç¼ºå°‘ author å‚æ•°")

    # æ£€æŸ¥ä½œè€…æ˜¯å¦å­˜åœ¨
    exists = db.query(CommitRecord.author_name).filter(
        CommitRecord.author_name == author
    ).first()
    if not exists:
        # å°è¯•ä»å‘˜å·¥åˆ—è¡¨ä¸­æŸ¥æ‰¾ï¼ˆå…è®¸æŸ¥æ— è®°å½•è€…ï¼‰
        employees = load_all_employees()
        if not any(e["name"] == author for e in employees):
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°è¯¥å¼€å‘è€…")

    # è®¾ç½®é»˜è®¤æ—¶é—´èŒƒå›´
    if days is not None:
        days = min(days, 180)  # æœ€å¤š180å¤©
        end_date_obj = date.today() - timedelta(days=1)  # æ˜¨å¤©
        start_date_obj = end_date_obj - timedelta(days=days-1)
    else:
        if start_date:
            start_date_obj = datetime.fromisoformat(start_date).date()
        else:
            start_date_obj = date.today() - timedelta(days=6)  # é»˜è®¤7å¤©

        if end_date:
            end_date_obj = datetime.fromisoformat(end_date).date()
        else:
            end_date_obj = date.today() - timedelta(days=1)

    # é˜²æ­¢æŸ¥è¯¢è¶…è¿‡180å¤©
    delta = (end_date_obj - start_date_obj).days
    if delta > 180:
        raise HTTPException(status_code=400, detail="æ—¶é—´èŒƒå›´ä¸èƒ½è¶…è¿‡180å¤©")

    return templates.TemplateResponse(
        "detail.html",
        {
            "request": request,
            "author": author,
            "days": days,
            "start_date": start_date_obj.isoformat() if start_date_obj else None,
            "end_date": end_date_obj.isoformat() if end_date_obj else None,
        }
    )


@app.get("/api/trends")
def get_trends(
    author: str = Query(..., description="å¼€å‘è€…å§“å"),
    days: int = Query(None, ge=1, le=180),
    start_date: str = Query(None),
    end_date: str = Query(None),
    db: Session = Depends(get_db)
):
    """
    è¿”å›å¼€å‘è€…æ¯æ—¥æäº¤è¶‹åŠ¿æ•°æ®ï¼ˆJSONï¼‰
    æ ¼å¼: { "dates": [...], "additions": [...], "deletions": [...] }
    """
    if not author:
        raise HTTPException(status_code=400, detail="ç¼ºå°‘ author å‚æ•°")

    # æ—¶é—´èŒƒå›´å¤„ç†
    if days is not None:
        days = min(days, 180)
        until = datetime.now().date() - timedelta(days=1)
        since = until - timedelta(days=days-1)
    else:
        since = datetime.fromisoformat(start_date).date() if start_date else None
        until = datetime.fromisoformat(end_date).date() if end_date else datetime.now().date() - timedelta(days=1)

    # éªŒè¯æ—¶é—´èŒƒå›´
    if not since or not until:
        since = until - timedelta(days=6)  # é»˜è®¤7å¤©

    if (until - since).days > 180:
        raise HTTPException(status_code=400, detail="æ—¶é—´èŒƒå›´ä¸èƒ½è¶…è¿‡180å¤©")

    # æ•°æ®åº“æŸ¥è¯¢ï¼šæŒ‰æ—¥æœŸèšåˆ additions å’Œ deletions
    result = (
        db.query(
            func.date(CommitRecord.commit_date).label("commit_date"),
            func.sum(CommitRecord.additions).label("additions"),
            func.sum(CommitRecord.deletions).label("deletions")
        )
        .filter(CommitRecord.author_name == author)
        .filter(func.date(CommitRecord.commit_date) >= since)
        .filter(func.date(CommitRecord.commit_date) <= until)
        .group_by(func.date(CommitRecord.commit_date))
        .order_by(func.date(CommitRecord.commit_date))
        .all()
    )

    # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨ï¼Œç¡®ä¿æ—¥æœŸè¿ç»­ï¼ˆå¯é€‰ï¼šè¡¥é›¶ï¼‰
    dates = []
    adds = []
    dels = []

    current = since
    print(current)
    result_dict = {
        datetime.strptime(r.commit_date, "%Y-%m-%d").date(): r
        for r in result
        if r.commit_date is not None
    }
    print(result_dict)

    while current <= until:
        if current in result_dict:
            row = result_dict[current]
            print(row)
            adds.append(int(row.additions))
            dels.append(int(row.deletions))
        else:
            adds.append(0)
            dels.append(0)
        dates.append(current.isoformat())
        current += timedelta(days=1)

    return {
        "dates": dates,
        "additions": adds,
        "deletions": dels
    }

    print(additions)


@app.post("/sync")
def trigger_sync():
    sync_yesterday_commits()
    return {"status": "success", "message": "æ•°æ®åŒæ­¥ä»»åŠ¡å·²æ‰§è¡Œ"}


@app.get("/health")
def health_check():
    return {"status": "healthy"}


def start_scheduler():
    # æ·»åŠ æ¯å¤© 8:00 æ‰§è¡Œçš„ä»»åŠ¡
    scheduler.add_job(
        func=sync_yesterday_commits,
        trigger="cron",
        hour=8,
        minute=0,
        timezone=timezone("Asia/Shanghai"),
        id="daily_sync",
        name="æ¯æ—¥ GitLab æäº¤åŒæ­¥",
        replace_existing=True,
        misfire_grace_time=60,  # âœ… å®¹å¿ 60 ç§’å»¶è¿Ÿ
        max_instances=1,  # âœ… é˜²æ­¢å¹¶å‘
        coalesce=True  # âœ… é”™è¿‡å¤šæ­¤åªæ‰§è¡Œä¸€æ¬¡
    )
    scheduler.start()
    print("âœ… å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨ï¼šæ¯å¤© 08:00 åŒæ­¥æ˜¨æ—¥æäº¤")
    atexit.register(lambda: scheduler.shutdown())


async def async_trigger_sync():
    print("â° [Scheduler] æ­£åœ¨æäº¤ sync_yesterday_commits åˆ°åå°çº¿ç¨‹...")
    loop = asyncio.get_event_loop()
    await loop.run_in_executor(executor, sync_yesterday_commits)
    print("â° [Scheduler] sync_yesterday_commits æäº¤å®Œæˆ")


# ================================
# âœ… å¼‚æ­¥æ‰§è¡ŒåŒæ­¥ä»»åŠ¡çš„åŒ…è£…å‡½æ•°
# ================================
async def run_sync_in_background():
    print("ğŸ”„ å¼€å§‹æ‰§è¡Œæ•°æ®åŒæ­¥ä»»åŠ¡...")
    try:
        sync_yesterday_commits()
        print("âœ… æ•°æ®åŒæ­¥ä»»åŠ¡å®Œæˆ")
    except Exception as e:
        print(f"âŒ æ•°æ®åŒæ­¥ä»»åŠ¡å¤±è´¥: {e}")


# æ·»åŠ è¯»å–excelçš„å‡½æ•°
EMPLOYEES_FILE = os.path.join(os.path.dirname(__file__), "employee.xlsx")


def load_all_employees() -> list:
    """
        ä» Excel æ–‡ä»¶è¯»å–æ‰€æœ‰å‘˜å·¥ï¼šå§“å + éƒ¨é—¨
        è¿”å›: [{"name": "å¼ ä¸‰", "department": "åç«¯ç»„"}, ...]
        """
    try:
        df = pd.read_excel(EMPLOYEES_FILE)
        df.columns = df.columns.str.strip()  # æ¸…ç†åˆ—åç©ºæ ¼

        if "å§“å" not in df.columns or "éƒ¨é—¨" not in df.columns:
            raise ValueError("Excel æ–‡ä»¶å¿…é¡»åŒ…å« 'å§“å' å’Œ 'éƒ¨é—¨' åˆ—")

        employees = []
        for _, row in df.iterrows():
            name = str(row["å§“å"]).strip()
            dept = str(row["éƒ¨é—¨"]).strip()
            if name:
                employees.append({"name": name, "department": dept})

        print(f"âœ… æˆåŠŸåŠ è½½ {len(employees)} åå‘˜å·¥: {employees}")
        return employees

    except Exception as e:
        print(f"âŒ è¯»å– employees.xlsx å¤±è´¥: {e}")
        return []


# ================================
# âœ… ä¿®æ”¹ç‚¹ï¼šå¯åŠ¨æ—¶ä¸é˜»å¡ï¼Œå¼‚æ­¥æ‰§è¡Œé¦–æ¬¡åŒæ­¥
# ================================
@app.on_event("startup")
async def startup_event():
    print("ğŸš€ åº”ç”¨å¯åŠ¨ä¸­...")
    print("âœ… åº”ç”¨å·²å¯åŠ¨ï¼ŒUvicorn æ­£åœ¨è¿è¡Œ...")

    # å¯åŠ¨å®šæ—¶ä»»åŠ¡
    start_scheduler()

    # æäº¤é¦–æ¬¡åŒæ­¥ä»»åŠ¡åˆ°äº‹ä»¶å¾ªç¯ï¼Œä¸é˜»å¡
    loop = asyncio.get_event_loop()
    loop.run_in_executor(None, sync_yesterday_commits)

    print("ğŸ“Œ é¦–æ¬¡æ•°æ®åŒæ­¥ä»»åŠ¡å·²æäº¤è‡³åå°æ‰§è¡Œ...")


@app.on_event("shutdown")
async def shutdown_event():
    print("ğŸ‘‹ åº”ç”¨æ­£åœ¨å…³é—­...")


# ================================
# ğŸ§© Jinja2 è¿‡æ»¤å™¨ï¼šç”¨äºåˆ†é¡µæ—¶ä¿ç•™æŸ¥è¯¢å‚æ•°
def update_query_params(*args, **updates):
    """
    Jinja2 è¿‡æ»¤å™¨ï¼šæ›´æ–°æŸ¥è¯¢å‚æ•°ã€‚
    ç”¨æ³•: {{ request.query_params | update_query(page=2, search="å¼ ") }}
    """
    if not args:
        return ""
    try:
        original = args[0]
        params = dict(original)
        params.update(updates)
        return "&".join(
            f"{k}={v}" for k, v in params.items()
            if v is not None and v != ""
        )
    except Exception as e:
        print(f"âŒ update_query_params error: {e}")
        return ""


# æ³¨å†Œè¿‡æ»¤å™¨
templates.env.filters["update_query"] = update_query_params

if __name__ == "__main__":
    uvicorn.run("app.main:app", host="127.0.0.1", port=8000, reload=False)
